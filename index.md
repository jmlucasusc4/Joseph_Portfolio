# Data Science Portfolio

Here are some of my best Data Science Projects. I have explored various machine-learning algorithms for different datasets. Feel free to contact me to learn more about my experience working with these projects.

***

[Examining the effect of environmental factors and weather on Bike rentals](https://github.com/jmlucasusc4/LinearRegressionProject/blob/main/Seoul_Bike_Linear_Regression_Project.ipynb)

<img src="images/seoul-bikes.jpeg?raw=true"/>
**Skills used:** - Pandas, Numpy, Matplotlib, sklearn, linear regression

**Project objective:** Predicting Bike rental demand on basis of weather and seasonal factors in advance to take appropiate measures which finally will result in bike utilization.


**Quantifiable result:** We could predict the Bike rental demand resulting in 46% accuracy.

- Used Linear Regression to predict the number of bikes rented in the city of Seoul
- The data had quite a few categorical variables which were encoded for use in the model
- Encoded categorical variables to numeric using Sklearn due to the presence of many string columns
- Fit a multiple linear regression model with high prediction accuracy through iteration

***

[Prediction of Bank Marketing Campaign using a logistic classifier](https://github.com/jmlucasusc4/LogisticRegression/blob/main/Bank_Logistic_RegressionProject.ipynb)

<img src="images/Bank_data.jpeg?raw=true"/>
**Skills used:** - Pandas, Numpy, Matplotlib, sklearn, logistic regression

**Project objective:** In this project I was provided with real world data which is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).


**Quantifiable result:** We could predict 90.6% **Accuracy** in UCI BANK Data.

- Used logistic regression to identify a customer will opt for term deposit or not 
- Classified outputs as yes or no by studying patterns in measured attributes of those customer response
- Used Logistic regression classifier & optimized the accuracy by using the ROC curve
- Explored a machine learning approach to bank data and find the prediction of Y

***

[Identifying symptoms of orthopedic patients as normal or abnormal](https://github.com/jmlucasusc4/KNN_NB_Project/blob/main/04_Knn_Nb_Project_ipynb.ipynb)

<img src="images/knee-brace-ortho.png?raw=true"/>
**Skills used:** - Pandas, Numpy, Matplotlib, sklearn, KNN and Naive Bayes

**Project objective:** Classifying Biomechanical Features of Orthopedic Patients based on provided features to decrease the time required for diagnosis.

**Quantifiable result:** We could predict the **Accuracy** of the KNN is 85.05% and **Accuracy** of the NB is 82.26% .

- Used the K Nearest Neighbours algorithm to classify a patient's condition as normal or abnormal based on various orthopedic parameters
- Compared predictive performance by fitting a Naive Bayes model to the data
- Used the Naive Bayes algorithm to classify a patient's condition as normal or abnormal based on various orthopedic parameters
- Selected best model based on train and test performance

***

[Using Decision Tree to classify the Iris Dataset](https://github.com/jmlucasusc4/Decision_Tree/blob/main/Decison_Tree_Example.ipynb)

<img src="images/Iris.png?raw=true"/>
**Skills used:** - Pandas, Numpy, Matplotlib, sklearn, Decison Tree algorithm

**Project objective** 

**Quantifiable result:** We could predict the ***Accuracy** of the DT Classifier to be 95.56%

- Used the Decision Tree algorithm to classify the species of iris flower on Iris dataset based on various parameters
- Compared predictive performance by fitting decision tree model to the data
- Used the Decision Tree algorithm to classify a iris flower species as Setosa, Versicolor, or Virginica based on various parameters
- Selected best model based on train and test performance

***

[Using Bagging and Boosting to classify the Talking Dataset](https://github.com/jmlucasusc4/Bagging_Boosting_Project/blob/main/Bagging_Boosting_Project_ipynb.ipynb)

<img src="images/talking.png?raw=true"/>
**Skills used:** - Pandas, Numpy, Matplotlib, Sklearn, Bagging and Boosting Classifier 

**Project objective:** Implementing Deep Neural Network with Keras for handwriting classification and recognition

**Quantifiable result:** We could predict the Bagging Classifier **Accuracy** to be 84.02% on AUC/ROC and Boosting Classifier **Accuracy** to be 93.20% on AUC/ROC.

- First apply the Bagging Classifier to talking dataset to find whether the customers were downloading the app or not.
- Compared predictive performance by fitting decision tree model to the data
- Used the Boosting Classifier to talking dataset to find whether the customers were downloading the app or not.
- In Bagging Classifier, we will use RandomForest; In Boosting Classifier, we will use XGBoost.
- Selected best model based on train and test performance

***

[Using Principal Component Analysis and Linear Regression to classify the Credit Card Fraud Dataset](https://github.com/jmlucasusc4/Credit_Card_Fraud)

<img src="images/Credit_card.jpeg?raw=true"/>
**Skills used:** - Pandas, Numpy, Matplotlib, sklearn, PCA components

**Project objective:**  Implementing PCA and Linear Regression to classify data from Credit Card Dataset.

**Quantifiable result:** We could predict the **accuracy** of the PCA to be 89.15% 

- First apply the Bagging Classifier to talking dataset to find whether the customers were downloading the app or not.
- Used sklearn to scale the data and produce means for data analysis. 
- Used the PCA Components to credit card fraud dataset to reduce the dimensions.
- Then, we will use pca.explained_variance_, singular values, and means to signal behavior.
- Used Matplotlib to graph the variance ratio.


***

[Identifying given picture is a Cat or a Dog](https://github.com/jmlucasusc4/CNN_Project)

<img src="images/Dog-and-Cat.jpeg?raw=true"/>
**Skills used:** -Python, Keras, Tensorflow, Pandas, Matplotlib

**Project objective**: Prediction of whether a given image is a Cat or a Dog using Convolutional Neural Networks which may be further implemented as a feature in a bigger project.

**Quantifiable result**: We could train the Convolutional Neural Network to attain a accuracy of 80% using 23 epochs.

- Added multiple convolution and pooling layers
- Training model on basis of given data
- Fitting the CNN to see if the provided image is dog or cat
***