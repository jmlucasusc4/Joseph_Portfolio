# Data Science Portfolio

Here are some of my best Data Science Projects. I have explored various machine-learning algorithms for different datasets. Feel free to contact me to learn more about my experience working with these projects.

***

[Examining the effect of environmental factors and weather on Bike rentals](https://github.com/jmlucasusc4/LinearRegressionProject/blob/main/Seoul_Bike_Linear_Regression_Project.ipynb)

<img src="images/seoul-bikes.jpeg?raw=true"/>
**Tools used** - Pandas, Numpy, Matplotlib, sklearn, linear regression

**Project objective** 

- Used Linear Regression to predict the number of bikes rented in the city of Seoul
- The data had quite a few categorical variables which were encoded for use in the model
- Encoded categorical variables to numeric using Sklearn due to the presence of many string columns
- Fit a multiple linear regression model with high prediction accuracy through iteration

**Project outcomes**
46% Accuracy in rental bike count.

***

[Diagnosis of Bank Marketing Campaign using a logistic classifier](https://github.com/jmlucasusc4/LogisticRegression/blob/main/Bank_Logistic_RegressionProject.ipynb)

<img src="images/Bank_data.jpeg?raw=true"/>
**Tools used** - Pandas, Numpy, Matplotlib, sklearn, logistic regression

**Project objective** 

- Used logistic regression to identify a customer will opt for term deposit or not 
- Classified outputs as yes or no by studying patterns in measured attributes of those customer response
- Used Logistic regression classifier & optimized the accuracy by using the ROC curve
- Explored a machine learning approach to bank data and find the prediction of Y

**Project outcomes**
90.6% Accuracy in UCI BANK Data.

***

[Identifying symptoms of orthopedic patients as normal or abnormal](https://github.com/jmlucasusc4/KNN_NB_Project/blob/main/04_Knn_Nb_Project_ipynb.ipynb)

<img src="images/knee-brace-ortho.png?raw=true"/>
**Tools used** - Pandas, Numpy, Matplotlib, sklearn, KNN and Naive Bayes

**Project objective** 

- Used the K Nearest Neighbours algorithm to classify a patient's condition as normal or abnormal based on various orthopedic parameters
- Compared predictive performance by fitting a Naive Bayes model to the data
- Used the Naive Bayes algorithm to classify a patient's condition as normal or abnormal based on various orthopedic parameters
- Selected best model based on train and test performance

**Project outcomes**
Accuracy of the KNN is 85.05%.
Accuracy of the NB is 82.26%

***

[Using Decision Tree to classify the Iris Dataset](https://github.com/jmlucasusc4/Decision_Tree/blob/main/Decison_Tree_Example.ipynb)

<img src="images/Iris.png?raw=true"/>
**Tools used** - Pandas, Numpy, Matplotlib, sklearn, Decison Tree algorithm

**Project objective** 

- Used the Decision Tree algorithm to classify the species of iris flower on Iris dataset based on various parameters
- Compared predictive performance by fitting decision tree model to the data
- Used the Decision Tree algorithm to classify a iris flower species as Setosa, Versicolor, or Virginica based on various parameters
- Selected best model based on train and test performance

**Project outcomes**
Accuracy of the DT Classifier is 95.56%

***

[Using Bagging and Boosting to classify the Talking Dataset](https://github.com/jmlucasusc4/Bagging_Boosting_Project/blob/main/Bagging_Boosting_Project_ipynb.ipynb)

<img src="images/talking.png?raw=true"/>
**Tools used** - Pandas, Numpy, Matplotlib, Sklearn, Bagging and Boosting Classifier 

**Project objective** 

- First apply the Bagging Classifier to talking dataset to find whether the customers were downloading the app or not.
- Compared predictive performance by fitting decision tree model to the data
- Used the Boosting Classifier to talking dataset to find whether the customers were downloading the app or not.
- In Bagging Classifier, we will use RandomForest; In Boosting Classifier, we will use XGBoost.
- Selected best model based on train and test performance

**Project outcomes**
Bagging Classifier Accuracy is 84.02% on AUC/ROC
Boosting Classifier Accuracy is 93.20% on AUC/ROC
***

[Using Principal Component Analysis and Linear Regression to classify the Credit Card Fraud Dataset](https://github.com/jmlucasusc4/Credit_Card_Fraud)

<img src="images/Credit_card.jpeg?raw=true"/>
**Tools used** - Pandas, Numpy, Matplotlib, sklearn, PCA components

**Project objective** 

- First apply the Bagging Classifier to talking dataset to find whether the customers were downloading the app or not.
- Used sklearn to scale the data and produce means for data analysis. 
- Used the PCA Components to credit card fraud dataset to reduce the dimensions.
- Then, we will use pca.explained_variance_, singular values, and means to signal behavior.
- Used Matplotlib to graph the variance ratio.

**Project outcomes**
The accuracy of the PCA is 89.15% 

***

[Identifying given picture is a Cat or a Dog](https://github.com/jmlucasusc4/CNN_Project)

<img src="images/Dog-and-Cat.jpeg?raw=true"/>
**Tools used** -Python, Keras, Tensorflow, Pandas, Matplotlib

**Project objective**: Prediction of whether a given image is a Cat or a Dog using Convolutional Neural Networks which may be further implemented as a feature in a bigger project.

**Quantifiable result**: We could train the Convolutional Neural Network to attain a accuracy of 80% using 23 epochs.

- Added multiple convolution and pooling layers
- Training model on basis of given data
- Fitting the CNN to see if the provided image is dog or cat
- Data Source: https://drive.google.com/drive/folders/15SG-chdqEwcrNAY39RTZJjvl-UwiZo_e?usp=sharing
***